{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpJwSvxFUHhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQXMB_J3UlqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"drive/My Drive/MSc BD & BA/Period 3/NLPy/data.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOE3AHkDVQK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from pprint import pprint\n",
        "from flair.data import Sentence\n",
        "from flair.embeddings import BertEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT8TQ7LCVtfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path, 'r') as f:\n",
        "    data = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Sq78hBWEf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utils\n",
        "\n",
        "def batch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def make_input(dictionnary, key):\n",
        "    line = dictionnary[key]\n",
        "    \n",
        "    message =  '[SOS] {} [EOS]'.format(line['message'])\n",
        "    \n",
        "    ans = '[SANS] {} [EANS]'.format(line['num_answers'])\n",
        "    cat = '[SCAT] {} [ECAT]'.format(line['category'])\n",
        "    country = '[SCOUNT] {} [ECOUNT]'.format(line['country'])\n",
        "    member = '[SMEM] {} [EMEM]'.format(line['member'])\n",
        "    solved = '[SSOL] {} [ESOL]'.format(line['is_solved'])\n",
        "    state = '[SSTAT] {} [ESTAT]'.format(line['visits'])\n",
        "    title = '[SOT] {} [EOT]'.format(line['titre'])\n",
        "    topic = '[STOP] {} [ETOP]'.format(line['topic_id'])\n",
        "    visits = '[SVIS] {} [EVIS]'.format(line['visits'])\n",
        "    votes = '[SVOT] {} [EVOT]'.format(line['votes'])\n",
        "    \n",
        "    inp = message + cat + country + member + solved + state\n",
        "    inp = inp + title + topic+ visits + votes\n",
        "    \n",
        "    return inp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu1194WNWIgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init Flair embeddings\n",
        "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
        "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
        "\n",
        "# init multilingual BERT\n",
        "bert_embedding = BertEmbeddings('bert-base-multilingual-cased')\n",
        "\n",
        "stacked_embeddings = StackedEmbeddings(\n",
        "    embeddings=[flair_forward_embedding, flair_backward_embedding, \n",
        "                bert_embedding\n",
        "               ]\n",
        "    )\n",
        "\n",
        "def embedding(sentence):\n",
        "    stacked_embeddings.embed(sentence)\n",
        "    return torch.Tensor([list(word.embedding) for word in sentence])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jf2ZDaNiOHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, label_size, batch_size, use_gpu):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.use_gpu = use_gpu\n",
        "        \n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.hidden2label = nn.Linear(hidden_dim, label_size)\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        if self.use_gpu:\n",
        "            h0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda())\n",
        "            c0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda())\n",
        "        else:\n",
        "            h0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
        "            c0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
        "        return (h0, c0)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = sentence\n",
        "        x = embeds.view(len(sentence), self.batch_size, -1)\n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        y  = self.hidden2label(lstm_out[-1])\n",
        "        return y\n",
        "\n",
        "      \n",
        "model = LSTMClassifier(embedding_dim = 7168, \n",
        "                       hidden_dim = 128, \n",
        "                       label_size = 1, \n",
        "                       batch_size = 1, \n",
        "                       use_gpu = True).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UN9rvu2YSC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63354dee-3285-4b6e-a1c4-426f247b429d"
      },
      "source": [
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "print(\"The model has {} trainable parameters\".format(count_parameters(model)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3736705 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFVU_f2JgqMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stochastic_train(model, optimizer, criterion, clip, data_source):\n",
        "    \n",
        "    losses = {}\n",
        "    mod_count = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for key in data_source.keys():\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        src = make_input(data_source, key)\n",
        "        trg = int(data_source[key]['is_best_answer'])\n",
        "        \n",
        "        # Got the minibatch\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Launching BERT embedding\n",
        "        src = embedding(Sentence(src)).to(device)\n",
        "        trg = torch.Tensor([trg]).to(device)\n",
        "        \n",
        "        # Launching LSTM forward\n",
        "        output = model(src).squeeze_(0)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        \n",
        "        \n",
        "        loss = criterion(torch.sigmoid(output), trg)\n",
        "        print('Loss is: ',loss.item())\n",
        "        print('Launching Backprop')\n",
        "        \n",
        "\n",
        "        loss.backward(retain_graph=True)\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        end_time = time.time()\n",
        "        batch_mins, batch_secs = batch_time(start_time, end_time)\n",
        "        \n",
        "        print('Time: {}:{}\\nLoss: {}'.format(batch_mins,batch_secs,loss.item()))\n",
        "        losses[key] = loss.item()\n",
        "        \n",
        "        \n",
        "        if int(key)+1% 100 == 0:\n",
        "            with (\"drive/My Drive/MSc BD & BA/Period 3/NLPy/results.json\", 'w') as f:\n",
        "                json.dump(losses, f)\n",
        "            torch.save(model.state_dict(), \n",
        "                       'drive/My Drive/MSc BD & BA/Period 3/NLPy/model{}.pt'.format(\n",
        "                       mod_count))\n",
        "            mod_count +=1\n",
        "        \n",
        "    return losses, mod_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaVdr3Z7hIlR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "72d22e54-7ff8-4eb1-82ad-6f1cf9e6886f"
      },
      "source": [
        "N_EPOCHS = 1\n",
        "CLIP = 1\n",
        "LOAD = False\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "train_loss, mod_count = stochastic_train(model, optimizer, criterion, CLIP, data)\n",
        "\n",
        "\n",
        "if LOAD:\n",
        "    model.load_state_dict(torch.load('drive/My Drive/MSc BD & BA/Period 3/NLPy/model{}.pt'.format(\n",
        "        mod_count)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Got the minibatch\n",
            "Launching BERT embedding\n",
            "Launching LSTM forward\n",
            "Loss is:  0.20415067672729492\n",
            "Launching Backprop\n",
            "Time: 0:1\n",
            "Loss: 0.20415067672729492\n",
            "Got the minibatch\n",
            "Launching BERT embedding\n",
            "Launching LSTM forward\n",
            "Loss is:  0.12183970212936401\n",
            "Launching Backprop\n",
            "Time: 0:1\n",
            "Loss: 0.12183970212936401\n",
            "Got the minibatch\n",
            "Launching BERT embedding\n",
            "Launching LSTM forward\n",
            "Loss is:  0.07801752537488937\n",
            "Launching Backprop\n",
            "Time: 0:2\n",
            "Loss: 0.07801752537488937\n",
            "Got the minibatch\n",
            "Launching BERT embedding\n",
            "Launching LSTM forward\n",
            "Loss is:  0.06253203004598618\n",
            "Launching Backprop\n",
            "Time: 0:2\n",
            "Loss: 0.06253203004598618\n",
            "Got the minibatch\n",
            "Launching BERT embedding\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-1f4fd5258258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstochastic_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-be04844a12bd>\u001b[0m in \u001b[0;36mstochastic_train\u001b[0;34m(model, optimizer, criterion, clip, data_source)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Launching BERT embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtrg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-074081b43732>\u001b[0m in \u001b[0;36membedding\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mstacked_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-074081b43732>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mstacked_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    434\u001b[0m                           \u001b[0;34m'iterations executed (and might lead to errors or silently give '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                           'incorrect results).', category=RuntimeWarning)\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn2uCda4OzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}