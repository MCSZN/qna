{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpJwSvxFUHhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQXMB_J3UlqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"drive/My Drive/MSc BD & BA/Period 3/NLPy/data.json\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOE3AHkDVQK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "from pprint import pprint\n",
        "from flair.data import Sentence\n",
        "from flair.embeddings import BertEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT8TQ7LCVtfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(path, 'r') as f:\n",
        "    data = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6Sq78hBWEf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utils\n",
        "\n",
        "def batch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def make_input(dictionnary, key):\n",
        "    line = dictionnary[key]\n",
        "    \n",
        "    message =  '[SOS] {} [EOS]'.format(line['message'])\n",
        "    \n",
        "    ans = '[SANS] {} [EANS]'.format(line['num_answers'])\n",
        "    cat = '[SCAT] {} [ECAT]'.format(line['category'])\n",
        "    country = '[SCOUNT] {} [ECOUNT]'.format(line['country'])\n",
        "    member = '[SMEM] {} [EMEM]'.format(line['member'])\n",
        "    solved = '[SSOL] {} [ESOL]'.format(line['is_solved'])\n",
        "    state = '[SSTAT] {} [ESTAT]'.format(line['visits'])\n",
        "    title = '[SOT] {} [EOT]'.format(line['titre'])\n",
        "    topic = '[STOP] {} [ETOP]'.format(line['topic_id'])\n",
        "    visits = '[SVIS] {} [EVIS]'.format(line['visits'])\n",
        "    votes = '[SVOT] {} [EVOT]'.format(line['votes'])\n",
        "    \n",
        "    inp = message + cat + country + member + solved + state\n",
        "    inp = inp + title + topic+ visits + votes\n",
        "    \n",
        "    return inp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu1194WNWIgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# init Flair embeddings\n",
        "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
        "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
        "\n",
        "# init multilingual BERT\n",
        "bert_embedding = BertEmbeddings('bert-base-multilingual-cased')\n",
        "\n",
        "stacked_embeddings = StackedEmbeddings(\n",
        "    embeddings=[flair_forward_embedding, flair_backward_embedding, \n",
        "                bert_embedding\n",
        "               ]\n",
        "    )\n",
        "\n",
        "def embedding(sentence):\n",
        "    stacked_embeddings.embed(sentence)\n",
        "    return torch.Tensor([list(word.embedding) for word in sentence])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jf2ZDaNiOHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, layers,label_size, batch_size, use_gpu):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.use_gpu = use_gpu\n",
        "        \n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, layers)\n",
        "        self.out = nn.Linear(hidden_dim, label_size)\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        if self.use_gpu:\n",
        "            h0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda())\n",
        "            c0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda())\n",
        "        else:\n",
        "            h0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
        "            c0 = Variable(torch.zeros(1, self.batch_size, self.hidden_dim))\n",
        "        return (h0, c0)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = sentence\n",
        "        x = embeds.view(len(sentence), self.batch_size, -1)\n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        y  = self.out(lstm_out[-1])\n",
        "        return y\n",
        "\n",
        "      \n",
        "model = LSTMClassifier(embedding_dim = 7168, \n",
        "                       hidden_dim = 128,\n",
        "                       layers = 3\n",
        "                       label_size = 1, \n",
        "                       batch_size = 1, \n",
        "                       use_gpu = True).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UN9rvu2YSC_",
        "colab_type": "code",
        "outputId": "63354dee-3285-4b6e-a1c4-426f247b429d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "print(\"The model has {} trainable parameters\".format(count_parameters(model)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3736705 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFVU_f2JgqMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stochastic_train(model, optimizer, criterion, clip, data_source):\n",
        "    \n",
        "    losses = {}\n",
        "    mod_count = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for key in data_source.keys():\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        src = make_input(data_source, key)\n",
        "        trg = int(data_source[key]['is_best_answer'])\n",
        "        \n",
        "        # Got the minibatch\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Launching BERT embedding\n",
        "        src = embedding(Sentence(src)).to(device)\n",
        "        trg = torch.Tensor([trg]).to(device)\n",
        "        \n",
        "        # Launching LSTM forward\n",
        "        output = model(src).squeeze_(0)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        \n",
        "        \n",
        "        loss = criterion(torch.sigmoid(output), trg)\n",
        "        print('Loss is: ',loss.item())\n",
        "        print('Launching Backprop')\n",
        "        \n",
        "\n",
        "        loss.backward(retain_graph=True)\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        end_time = time.time()\n",
        "        batch_mins, batch_secs = batch_time(start_time, end_time)\n",
        "        \n",
        "        print('Time: {}:{}\\nLoss: {}'.format(batch_mins,batch_secs,loss.item()))\n",
        "        losses[key] = loss.item()\n",
        "        \n",
        "        \n",
        "        if int(key)+1% 5000 == 0:\n",
        "            with (\"drive/My Drive/MSc BD & BA/Period 3/NLPy/results.json\", 'w') as f:\n",
        "                json.dump(losses, f)\n",
        "            torch.save(model.state_dict(), \n",
        "                       'drive/My Drive/MSc BD & BA/Period 3/NLPy/model{}.pt'.format(\n",
        "                       mod_count))\n",
        "            mod_count +=1\n",
        "        \n",
        "    return losses, mod_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaVdr3Z7hIlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_EPOCHS = 1\n",
        "CLIP = 1\n",
        "LOAD = False\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "train_loss, mod_count = stochastic_train(model, optimizer, criterion, CLIP, data)\n",
        "\n",
        "\n",
        "if LOAD:\n",
        "    model.load_state_dict(torch.load('drive/My Drive/MSc BD & BA/Period 3/NLPy/model{}.pt'.format(\n",
        "        mod_count)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtn2uCda4OzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}